"""
ì‹¤ì‹œê°„ í•™ìŠµ ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
Active Learningê³¼ Online Fine-tuningì„ í†µí•œ ì§€ì†ì  ì„±ëŠ¥ ê°œì„ 
"""

import os
import cv2
import numpy as np
from ultralytics import YOLO
import torch
from pathlib import Path
import json
import time
from datetime import datetime
import threading
import queue
from typing import List, Dict, Optional, Tuple
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import pandas as pd
from collections import deque
import pickle
import hashlib
import warnings
warnings.filterwarnings('ignore')


class ActiveLearningManager:
    """
    Active Learning ê´€ë¦¬ì
    ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œì„ ì„ ë³„í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ ê·¹ëŒ€í™”
    """
    
    def __init__(self, uncertainty_threshold=0.3, sample_buffer_size=100):
        """
        ì´ˆê¸°í™”
        
        Args:
            uncertainty_threshold: ë¶ˆí™•ì‹¤ì„± ì„ê³„ê°’
            sample_buffer_size: ìƒ˜í”Œ ë²„í¼ í¬ê¸°
        """
        self.uncertainty_threshold = uncertainty_threshold
        self.sample_buffer = deque(maxlen=sample_buffer_size)
        self.selected_samples = []
        self.learning_stats = {
            'total_samples': 0,
            'uncertain_samples': 0,
            'selected_for_training': 0
        }
        
    def calculate_uncertainty(self, detections):
        """
        ê²€ì¶œ ê²°ê³¼ì˜ ë¶ˆí™•ì‹¤ì„± ê³„ì‚°
        
        Args:
            detections: ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë¶ˆí™•ì‹¤ì„± ì ìˆ˜ (0~1)
        """
        if not detections:
            return 1.0  # ì•„ë¬´ê²ƒë„ ê²€ì¶œ ëª»í•œ ê²½ìš° ìµœëŒ€ ë¶ˆí™•ì‹¤ì„±
        
        confidences = [d.get('confidence', 0) for d in detections]
        
        # ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì„ ì¡°í•©í•œ ë¶ˆí™•ì‹¤ì„± ê³„ì‚°
        uncertainty_metrics = {
            'low_confidence': 1.0 - np.mean(confidences) if confidences else 1.0,
            'high_variance': np.std(confidences) if len(confidences) > 1 else 0,
            'detection_count': 1.0 / (1 + len(detections))  # ê²€ì¶œ ìˆ˜ê°€ ì ì„ìˆ˜ë¡ ë¶ˆí™•ì‹¤
        }
        
        # ê°€ì¤‘ í‰ê· 
        weights = {'low_confidence': 0.5, 'high_variance': 0.3, 'detection_count': 0.2}
        uncertainty = sum(weights[k] * v for k, v in uncertainty_metrics.items())
        
        return min(1.0, uncertainty)
    
    def should_add_sample(self, image_path, detections):
        """
        ìƒ˜í”Œì„ í•™ìŠµ ë°ì´í„°ì— ì¶”ê°€í• ì§€ ê²°ì •
        
        Args:
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            detections: ê²€ì¶œ ê²°ê³¼
        
        Returns:
            ì¶”ê°€ ì—¬ë¶€ (bool)
        """
        uncertainty = self.calculate_uncertainty(detections)
        
        self.learning_stats['total_samples'] += 1
        
        if uncertainty > self.uncertainty_threshold:
            self.learning_stats['uncertain_samples'] += 1
            
            # ì¤‘ë³µ ì²´í¬ (ì´ë¯¸ì§€ í•´ì‹œ ê¸°ë°˜)
            img_hash = self._get_image_hash(image_path)
            
            if img_hash not in [s['hash'] for s in self.sample_buffer]:
                self.sample_buffer.append({
                    'path': image_path,
                    'detections': detections,
                    'uncertainty': uncertainty,
                    'timestamp': datetime.now(),
                    'hash': img_hash
                })
                
                self.learning_stats['selected_for_training'] += 1
                return True
        
        return False
    
    def _get_image_hash(self, image_path):
        """ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚°"""
        with open(image_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def get_training_batch(self, batch_size=16):
        """
        í•™ìŠµìš© ë°°ì¹˜ ì„ íƒ
        
        Args:
            batch_size: ë°°ì¹˜ í¬ê¸°
        
        Returns:
            ì„ íƒëœ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
        """
        # ë¶ˆí™•ì‹¤ì„±ì´ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_samples = sorted(self.sample_buffer, 
                              key=lambda x: x['uncertainty'], 
                              reverse=True)
        
        # ìƒìœ„ batch_sizeê°œ ì„ íƒ
        batch = sorted_samples[:batch_size]
        
        # ì„ íƒëœ ìƒ˜í”Œ ì œê±°
        for sample in batch:
            if sample in self.sample_buffer:
                self.sample_buffer.remove(sample)
        
        return batch
    
    def get_statistics(self):
        """í•™ìŠµ í†µê³„ ë°˜í™˜"""
        return {
            **self.learning_stats,
            'buffer_size': len(self.sample_buffer),
            'selection_rate': self.learning_stats['selected_for_training'] / 
                            max(1, self.learning_stats['total_samples'])
        }


class OnlineFineTuner:
    """
    ì˜¨ë¼ì¸ íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œ
    ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸
    """
    
    def __init__(self, base_model="yolo11n.pt", update_frequency=50):
        """
        ì´ˆê¸°í™”
        
        Args:
            base_model: ê¸°ë³¸ ëª¨ë¸
            update_frequency: ì—…ë°ì´íŠ¸ ì£¼ê¸° (ìƒ˜í”Œ ìˆ˜)
        """
        self.base_model = base_model
        self.current_model = YOLO(base_model)
        self.update_frequency = update_frequency
        self.update_count = 0
        self.training_queue = queue.Queue()
        self.is_training = False
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_history = {
            'timestamps': [],
            'mAP': [],
            'precision': [],
            'recall': [],
            'loss': []
        }
        
        # ëª¨ë¸ ë²„ì „ ê´€ë¦¬
        self.model_versions = []
        self.current_version = 0
        
        print(f"ğŸ”„ ì˜¨ë¼ì¸ íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   ê¸°ë³¸ ëª¨ë¸: {base_model}")
        print(f"   ì—…ë°ì´íŠ¸ ì£¼ê¸°: {update_frequency} samples")
    
    def add_training_sample(self, image_path, annotations):
        """
        í•™ìŠµ ìƒ˜í”Œ ì¶”ê°€
        
        Args:
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            annotations: ì–´ë…¸í…Œì´ì…˜ ë°ì´í„°
        """
        self.training_queue.put({
            'image': image_path,
            'annotations': annotations,
            'timestamp': datetime.now()
        })
    
    def start_training_thread(self):
        """ë°±ê·¸ë¼ìš´ë“œ í•™ìŠµ ìŠ¤ë ˆë“œ ì‹œì‘"""
        if not self.is_training:
            self.is_training = True
            thread = threading.Thread(target=self._training_loop, daemon=True)
            thread.start()
            print("ğŸ¯ ë°±ê·¸ë¼ìš´ë“œ í•™ìŠµ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    def _training_loop(self):
        """ë°±ê·¸ë¼ìš´ë“œ í•™ìŠµ ë£¨í”„"""
        batch = []
        
        while self.is_training:
            try:
                # íì—ì„œ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
                sample = self.training_queue.get(timeout=1)
                batch.append(sample)
                
                # ë°°ì¹˜ê°€ ì°¨ë©´ í•™ìŠµ
                if len(batch) >= self.update_frequency:
                    self._perform_update(batch)
                    batch = []
                    
            except queue.Empty:
                # íê°€ ë¹„ì–´ìˆìœ¼ë©´ ëŒ€ê¸°
                time.sleep(1)
            except Exception as e:
                print(f"âŒ í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    def _perform_update(self, batch):
        """
        ëª¨ë¸ ì—…ë°ì´íŠ¸ ìˆ˜í–‰
        
        Args:
            batch: í•™ìŠµ ìƒ˜í”Œ ë°°ì¹˜
        """
        print(f"\nğŸ”„ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {len(batch)})")
        
        try:
            # ì„ì‹œ ë°ì´í„°ì…‹ ìƒì„±
            temp_dataset = self._create_temp_dataset(batch)
            
            # íŒŒì¸íŠœë‹ ìˆ˜í–‰ (ì§§ì€ ì—í­)
            results = self.current_model.train(
                data=temp_dataset,
                epochs=5,  # ë¹ ë¥¸ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ì§§ê²Œ
                batch=len(batch),
                verbose=False,
                device=0 if torch.cuda.is_available() else 'cpu'
            )
            
            # ì„±ëŠ¥ ê¸°ë¡
            self.performance_history['timestamps'].append(datetime.now())
            self.performance_history['mAP'].append(results.box.map if hasattr(results, 'box') else 0)
            self.performance_history['loss'].append(results.loss if hasattr(results, 'loss') else 0)
            
            # ëª¨ë¸ ë²„ì „ ì €ì¥
            self.save_model_version()
            
            self.update_count += 1
            print(f"âœ… ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ (ë²„ì „: {self.current_version})")
            
        except Exception as e:
            print(f"âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _create_temp_dataset(self, batch):
        """ì„ì‹œ ë°ì´í„°ì…‹ ìƒì„±"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        # ì—¬ê¸°ì„œëŠ” ê²½ë¡œë§Œ ë°˜í™˜
        temp_dir = Path("temp_dataset") / f"batch_{self.update_count}"
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        # ë°ì´í„° ì €ì¥ ë¡œì§...
        
        return str(temp_dir / "dataset.yaml")
    
    def save_model_version(self):
        """ëª¨ë¸ ë²„ì „ ì €ì¥"""
        version_path = f"model_versions/v{self.current_version}.pt"
        os.makedirs("model_versions", exist_ok=True)
        
        self.current_model.save(version_path)
        
        self.model_versions.append({
            'version': self.current_version,
            'path': version_path,
            'timestamp': datetime.now(),
            'performance': {
                'mAP': self.performance_history['mAP'][-1] if self.performance_history['mAP'] else 0
            }
        })
        
        self.current_version += 1
    
    def rollback_to_version(self, version):
        """íŠ¹ì • ë²„ì „ìœ¼ë¡œ ë¡¤ë°±"""
        for v in self.model_versions:
            if v['version'] == version:
                self.current_model = YOLO(v['path'])
                self.current_version = version
                print(f"âœ… ë²„ì „ {version}ìœ¼ë¡œ ë¡¤ë°± ì™„ë£Œ")
                return True
        
        print(f"âŒ ë²„ì „ {version}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    def get_best_model(self):
        """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë°˜í™˜"""
        if not self.model_versions:
            return self.current_model
        
        best_version = max(self.model_versions, 
                          key=lambda x: x['performance']['mAP'])
        
        return YOLO(best_version['path'])


class RealTimeMonitor:
    """
    ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
    """
    
    def __init__(self, window_size=100):
        """
        ì´ˆê¸°í™”
        
        Args:
            window_size: ëª¨ë‹ˆí„°ë§ ìœˆë„ìš° í¬ê¸°
        """
        self.window_size = window_size
        self.metrics_buffer = {
            'fps': deque(maxlen=window_size),
            'detections': deque(maxlen=window_size),
            'confidence': deque(maxlen=window_size),
            'processing_time': deque(maxlen=window_size)
        }
        
        self.alerts = []
        self.thresholds = {
            'min_fps': 20,
            'min_confidence': 0.5,
            'max_processing_time': 100  # ms
        }
        
        # ì‹œê°í™” ì„¤ì •
        self.fig = None
        self.axes = None
        self.lines = {}
        
    def update_metrics(self, fps, detections, avg_confidence, processing_time):
        """
        ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        
        Args:
            fps: ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜
            detections: ê²€ì¶œ ìˆ˜
            avg_confidence: í‰ê·  ì‹ ë¢°ë„
            processing_time: ì²˜ë¦¬ ì‹œê°„ (ms)
        """
        self.metrics_buffer['fps'].append(fps)
        self.metrics_buffer['detections'].append(detections)
        self.metrics_buffer['confidence'].append(avg_confidence)
        self.metrics_buffer['processing_time'].append(processing_time)
        
        # ì•ŒëŒ ì²´í¬
        self._check_alerts()
    
    def _check_alerts(self):
        """ì„±ëŠ¥ ì•ŒëŒ ì²´í¬"""
        current_metrics = {
            'fps': np.mean(self.metrics_buffer['fps']) if self.metrics_buffer['fps'] else 0,
            'confidence': np.mean(self.metrics_buffer['confidence']) if self.metrics_buffer['confidence'] else 0,
            'processing_time': np.mean(self.metrics_buffer['processing_time']) if self.metrics_buffer['processing_time'] else 0
        }
        
        # FPS ì²´í¬
        if current_metrics['fps'] < self.thresholds['min_fps']:
            self.alerts.append({
                'type': 'LOW_FPS',
                'value': current_metrics['fps'],
                'threshold': self.thresholds['min_fps'],
                'timestamp': datetime.now()
            })
        
        # ì‹ ë¢°ë„ ì²´í¬
        if current_metrics['confidence'] < self.thresholds['min_confidence']:
            self.alerts.append({
                'type': 'LOW_CONFIDENCE',
                'value': current_metrics['confidence'],
                'threshold': self.thresholds['min_confidence'],
                'timestamp': datetime.now()
            })
    
    def create_dashboard(self):
        """ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        plt.ion()
        self.fig, self.axes = plt.subplots(2, 2, figsize=(12, 8))
        self.fig.suptitle('Real-Time Performance Monitor', fontsize=16)
        
        # FPS ê·¸ë˜í”„
        self.axes[0, 0].set_title('FPS')
        self.axes[0, 0].set_xlabel('Time')
        self.axes[0, 0].set_ylabel('Frames/sec')
        self.lines['fps'], = self.axes[0, 0].plot([], [], 'b-')
        
        # ê²€ì¶œ ìˆ˜ ê·¸ë˜í”„
        self.axes[0, 1].set_title('Detections')
        self.axes[0, 1].set_xlabel('Time')
        self.axes[0, 1].set_ylabel('Count')
        self.lines['detections'], = self.axes[0, 1].plot([], [], 'g-')
        
        # ì‹ ë¢°ë„ ê·¸ë˜í”„
        self.axes[1, 0].set_title('Average Confidence')
        self.axes[1, 0].set_xlabel('Time')
        self.axes[1, 0].set_ylabel('Confidence')
        self.lines['confidence'], = self.axes[1, 0].plot([], [], 'r-')
        
        # ì²˜ë¦¬ ì‹œê°„ ê·¸ë˜í”„
        self.axes[1, 1].set_title('Processing Time')
        self.axes[1, 1].set_xlabel('Time')
        self.axes[1, 1].set_ylabel('Time (ms)')
        self.lines['processing_time'], = self.axes[1, 1].plot([], [], 'm-')
        
        plt.tight_layout()
    
    def update_dashboard(self):
        """ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸"""
        if self.fig is None:
            self.create_dashboard()
        
        for key in self.metrics_buffer:
            if self.metrics_buffer[key]:
                x = list(range(len(self.metrics_buffer[key])))
                y = list(self.metrics_buffer[key])
                
                self.lines[key].set_data(x, y)
                
                # ì¶• ë²”ìœ„ ì¡°ì •
                ax_idx = list(self.metrics_buffer.keys()).index(key)
                ax = self.axes[ax_idx // 2, ax_idx % 2]
                ax.relim()
                ax.autoscale_view()
        
        self.fig.canvas.draw()
        self.fig.canvas.flush_events()
    
    def generate_report(self):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'metrics': {},
            'alerts': self.alerts[-10:]  # ìµœê·¼ 10ê°œ ì•ŒëŒ
        }
        
        for key in self.metrics_buffer:
            if self.metrics_buffer[key]:
                report['metrics'][key] = {
                    'mean': float(np.mean(self.metrics_buffer[key])),
                    'std': float(np.std(self.metrics_buffer[key])),
                    'min': float(np.min(self.metrics_buffer[key])),
                    'max': float(np.max(self.metrics_buffer[key]))
                }
        
        return report


class IntegratedLearningSystem:
    """
    í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ
    Active Learning + Online Fine-tuning + Real-time Monitoring
    """
    
    def __init__(self, base_model="yolo11n.pt"):
        """
        ì´ˆê¸°í™”
        
        Args:
            base_model: ê¸°ë³¸ ëª¨ë¸
        """
        self.base_model = base_model
        self.detector = YOLO(base_model)
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.active_learner = ActiveLearningManager()
        self.online_tuner = OnlineFineTuner(base_model)
        self.monitor = RealTimeMonitor()
        
        # ìƒíƒœ
        self.is_running = False
        self.frame_count = 0
        self.start_time = None
        
        print("ğŸš€ í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_frame(self, frame):
        """
        í”„ë ˆì„ ì²˜ë¦¬
        
        Args:
            frame: ì…ë ¥ í”„ë ˆì„ (numpy array)
        
        Returns:
            ì²˜ë¦¬ëœ í”„ë ˆì„, ê²€ì¶œ ê²°ê³¼
        """
        start_time = time.time()
        
        # ê²€ì¶œ ìˆ˜í–‰
        results = self.detector(frame, verbose=False)
        
        # ê²€ì¶œ ê²°ê³¼ íŒŒì‹±
        detections = []
        if results[0].boxes is not None:
            for box in results[0].boxes:
                detections.append({
                    'bbox': box.xyxy[0].cpu().numpy(),
                    'confidence': float(box.conf[0]),
                    'class': int(box.cls[0])
                })
        
        # Active Learning ì²´í¬
        if self.active_learner.should_add_sample('current_frame', detections):
            # í•™ìŠµ íì— ì¶”ê°€
            self.online_tuner.add_training_sample('current_frame', detections)
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        processing_time = (time.time() - start_time) * 1000  # ms
        fps = 1000 / processing_time if processing_time > 0 else 0
        avg_confidence = np.mean([d['confidence'] for d in detections]) if detections else 0
        
        # ëª¨ë‹ˆí„°ë§ ì—…ë°ì´íŠ¸
        self.monitor.update_metrics(fps, len(detections), avg_confidence, processing_time)
        
        # í”„ë ˆì„ì— ê²°ê³¼ ê·¸ë¦¬ê¸°
        annotated_frame = self._annotate_frame(frame, detections)
        
        self.frame_count += 1
        
        return annotated_frame, detections
    
    def _annotate_frame(self, frame, detections):
        """í”„ë ˆì„ì— ê²€ì¶œ ê²°ê³¼ í‘œì‹œ"""
        annotated = frame.copy()
        
        for det in detections:
            x1, y1, x2, y2 = det['bbox'].astype(int)
            conf = det['confidence']
            
            # ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ë¼ë²¨
            label = f"Class {det['class']}: {conf:.2f}"
            cv2.putText(annotated, label, (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # í†µê³„ ì •ë³´ í‘œì‹œ
        stats = self.active_learner.get_statistics()
        info_text = f"Frames: {self.frame_count} | Uncertain: {stats['uncertain_samples']} | Buffer: {stats['buffer_size']}"
        cv2.putText(annotated, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return annotated
    
    def start(self, video_source=0):
        """
        ì‹œìŠ¤í…œ ì‹œì‘
        
        Args:
            video_source: ë¹„ë””ì˜¤ ì†ŒìŠ¤ (0: ì›¹ìº , íŒŒì¼ ê²½ë¡œ)
        """
        print("ğŸ¬ ì‹œìŠ¤í…œ ì‹œì‘...")
        
        self.is_running = True
        self.start_time = time.time()
        
        # ë°±ê·¸ë¼ìš´ë“œ í•™ìŠµ ì‹œì‘
        self.online_tuner.start_training_thread()
        
        # ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìƒì„±
        self.monitor.create_dashboard()
        
        # ë¹„ë””ì˜¤ ìº¡ì²˜
        cap = cv2.VideoCapture(video_source)
        
        print("Press 'q' to quit, 's' to save snapshot, 'r' to generate report")
        
        while self.is_running:
            ret, frame = cap.read()
            if not ret:
                break
            
            # í”„ë ˆì„ ì²˜ë¦¬
            annotated_frame, detections = self.process_frame(frame)
            
            # ê²°ê³¼ í‘œì‹œ
            cv2.imshow('Integrated Learning System', annotated_frame)
            
            # ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸ (10í”„ë ˆì„ë§ˆë‹¤)
            if self.frame_count % 10 == 0:
                self.monitor.update_dashboard()
            
            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                self._save_snapshot(annotated_frame)
            elif key == ord('r'):
                self._generate_system_report()
        
        # ì •ë¦¬
        cap.release()
        cv2.destroyAllWindows()
        self.is_running = False
        
        print("âœ… ì‹œìŠ¤í…œ ì¢…ë£Œ")
    
    def _save_snapshot(self, frame):
        """ìŠ¤ëƒ…ìƒ· ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"snapshots/snapshot_{timestamp}.jpg"
        os.makedirs("snapshots", exist_ok=True)
        cv2.imwrite(filename, frame)
        print(f"ğŸ“¸ ìŠ¤ëƒ…ìƒ· ì €ì¥: {filename}")
    
    def _generate_system_report(self):
        """ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = {
            'system_info': {
                'runtime': time.time() - self.start_time,
                'frames_processed': self.frame_count,
                'model_version': self.online_tuner.current_version
            },
            'active_learning': self.active_learner.get_statistics(),
            'performance': self.monitor.generate_report(),
            'model_history': self.online_tuner.performance_history
        }
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"reports/system_report_{timestamp}.json"
        os.makedirs("reports", exist_ok=True)
        
        with open(filename, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"ğŸ“Š ë¦¬í¬íŠ¸ ìƒì„±: {filename}")
        
        # ìš”ì•½ ì¶œë ¥
        print("\n=== ì‹œìŠ¤í…œ ìš”ì•½ ===")
        print(f"ì‹¤í–‰ ì‹œê°„: {report['system_info']['runtime']:.1f}ì´ˆ")
        print(f"ì²˜ë¦¬ í”„ë ˆì„: {report['system_info']['frames_processed']}")
        print(f"ë¶ˆí™•ì‹¤ ìƒ˜í”Œ: {report['active_learning']['uncertain_samples']}")
        print(f"ëª¨ë¸ ë²„ì „: {report['system_info']['model_version']}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ¤– YOLO11 ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # ì‹œìŠ¤í…œ ìƒì„±
    system = IntegratedLearningSystem(base_model="yolo11n.pt")
    
    print("\nê¸°ëŠ¥:")
    print("- Active Learning: ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œ ìë™ ì„ ë³„")
    print("- Online Fine-tuning: ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸")
    print("- Real-time Monitoring: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
    print("- Auto-annotation: ìë™ ë¼ë²¨ë§")
    
    print("\nì‚¬ìš©ë²•:")
    print("1. system.start(0) - ì›¹ìº ìœ¼ë¡œ ì‹œì‘")
    print("2. system.start('video.mp4') - ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì‹œì‘")
    
    # ì˜ˆì œ ì‹¤í–‰
    # system.start(0)  # ì›¹ìº  ì‚¬ìš©


if __name__ == "__main__":
    main()