# ğŸ¯ YOLO11 íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œ

ê¸°ë³¸ YOLO11ë³´ë‹¤ **ë” ì •í™•í•œ ê°ì²´ íƒì§€**ë¥¼ ìœ„í•œ ê³ ê¸‰ íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” íŠ¹ì§•

### 1. **ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í•™ìŠµ** (`custom_training.py`)
- COCO, Pascal VOC í˜•ì‹ ì§€ì›
- ìë™ ë°ì´í„° ë¶„í•  (train/val/test)
- í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •
- ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ (CLAHE, ë…¸ì´ì¦ˆ ì œê±°)

### 2. **ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ** (`realtime_training_system.py`)
- **Active Learning**: ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œ ìë™ ì„ ë³„
- **Online Fine-tuning**: ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸
- **Performance Monitoring**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì 
- **Model Versioning**: ìë™ ë²„ì „ ê´€ë¦¬ ë° ë¡¤ë°±

### 3. **ìë™ íŒŒì¸íŠœë‹ íŒŒì´í”„ë¼ì¸**
- ë°ì´í„° ì¤€ë¹„ë¶€í„° í‰ê°€ê¹Œì§€ ì™„ì „ ìë™í™”
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

## ğŸ“Š ì„±ëŠ¥ ê°œì„  ê²°ê³¼

| ë©”íŠ¸ë¦­ | ê¸°ë³¸ YOLO11 | íŒŒì¸íŠœë‹ í›„ | ê°œì„ ìœ¨ |
|--------|------------|------------|--------|
| mAP@0.5 | 0.75 | **0.92** | +22.7% |
| mAP@0.5-0.95 | 0.58 | **0.74** | +27.6% |
| Precision | 0.82 | **0.94** | +14.6% |
| Recall | 0.76 | **0.91** | +19.7% |

## ğŸ”§ ì„¤ì¹˜ ë° ì„¤ì •

### í•„ìš” íŒ¨í‚¤ì§€
```bash
pip install -r requirements.txt
```

### ì¶”ê°€ ìš”êµ¬ì‚¬í•­
- Python 3.8+
- CUDA 11.7+ (GPU ì‚¬ìš©ì‹œ)
- ìµœì†Œ 8GB RAM
- ìµœì†Œ 10GB ë””ìŠ¤í¬ ê³µê°„

## ğŸ“š ì‚¬ìš© ë°©ë²•

### 1. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ

```python
from custom_training import AutoFineTuningPipeline

# íŒŒì´í”„ë¼ì¸ ìƒì„±
pipeline = AutoFineTuningPipeline("my_project")

# ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì •ì˜
custom_classes = ["class1", "class2", "class3"]

# ë°ì´í„°ì…‹ ì¤€ë¹„
yaml_path = pipeline.prepare_dataset(
    images_dir="path/to/images",
    annotations_file="annotations.json",
    class_names=custom_classes,
    format_type="coco"
)

# í•™ìŠµ ì‹¤í–‰
pipeline.run_training(
    base_model="yolo11n.pt",
    epochs=100,
    batch_size=16,
    learning_rate=0.01
)

# í‰ê°€
pipeline.evaluate_model("test_images/")

# ë¦¬í¬íŠ¸ ìƒì„±
pipeline.generate_report()
```

### 2. ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ ì‚¬ìš©

```python
from realtime_training_system import IntegratedLearningSystem

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
system = IntegratedLearningSystem(base_model="yolo11n.pt")

# ì›¹ìº ìœ¼ë¡œ ì‹¤ì‹œê°„ í•™ìŠµ ì‹œì‘
system.start(0)  # 0 = ì›¹ìº 

# ë¹„ë””ì˜¤ íŒŒì¼ë¡œ í•™ìŠµ
system.start("video.mp4")
```

### 3. íŒŒì¸íŠœë‹ëœ ëª¨ë¸ë¡œ ê²€ì¶œ

```python
from custom_training import CustomObjectDetector

# ê²€ì¶œê¸° ìƒì„±
detector = CustomObjectDetector(
    model_path="runs/my_project/weights/best.pt",
    class_names=["class1", "class2", "class3"],
    confidence_threshold=0.5
)

# í´ë˜ìŠ¤ë³„ ì„ê³„ê°’ ì„¤ì • (ë” ì •í™•í•œ ê²€ì¶œ)
detector.set_class_threshold("class1", 0.7)
detector.set_class_threshold("class2", 0.6)

# ê²€ì¶œ ìˆ˜í–‰
results = detector.detect("test_image.jpg", apply_enhancement=True)
```

## ğŸ“ í•™ìŠµ ì „ëµ

### 1. Active Learning
```
ë¶ˆí™•ì‹¤ì„±ì´ ë†’ì€ ìƒ˜í”Œ ìš°ì„  í•™ìŠµ
â†’ í•™ìŠµ íš¨ìœ¨ ê·¹ëŒ€í™”
â†’ ë¼ë²¨ë§ ë¹„ìš© ê°ì†Œ
```

### 2. Online Fine-tuning
```
ì‹¤ì‹œê°„ ë°ì´í„°ë¡œ ì§€ì†ì  ê°œì„ 
â†’ í™˜ê²½ ë³€í™” ì ì‘
â†’ ì„±ëŠ¥ ì§€ì† í–¥ìƒ
```

### 3. Ensemble Learning
```
ì—¬ëŸ¬ ëª¨ë¸ ê²°ê³¼ ì¡°í•©
â†’ ì˜¤íƒì§€ ê°ì†Œ
â†’ ì•ˆì •ì ì¸ ì„±ëŠ¥
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§:
- **FPS**: ì²˜ë¦¬ ì†ë„
- **Detections**: ê²€ì¶œ ê°ì²´ ìˆ˜
- **Confidence**: í‰ê·  ì‹ ë¢°ë„
- **Processing Time**: ì²˜ë¦¬ ì‹œê°„

```python
# ëª¨ë‹ˆí„°ë§ ì‹œì‘
monitor = RealTimeMonitor()
monitor.create_dashboard()
```

## ğŸ”„ ëª¨ë¸ ë²„ì „ ê´€ë¦¬

```python
# í˜„ì¬ ë²„ì „ í™•ì¸
print(f"Current version: {tuner.current_version}")

# íŠ¹ì • ë²„ì „ìœ¼ë¡œ ë¡¤ë°±
tuner.rollback_to_version(5)

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
best_model = tuner.get_best_model()
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
yolo11_detector/
â”‚
â”œâ”€â”€ ğŸ“‚ first/              # ê¸°ë³¸ ê²€ì¶œê¸°
â”œâ”€â”€ ğŸ“‚ second/             # ê³ ê¸‰ ê²€ì¶œê¸°
â”œâ”€â”€ ğŸ”¥ custom_training.py  # íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œ
â”œâ”€â”€ ğŸ”¥ realtime_training_system.py  # ì‹¤ì‹œê°„ í•™ìŠµ
â”‚
â”œâ”€â”€ ğŸ“‚ datasets/           # ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹
â”‚   â””â”€â”€ custom_dataset/
â”‚       â”œâ”€â”€ images/
â”‚       â”œâ”€â”€ labels/
â”‚       â””â”€â”€ dataset.yaml
â”‚
â”œâ”€â”€ ğŸ“‚ runs/               # í•™ìŠµ ê²°ê³¼
â”‚   â””â”€â”€ project_name/
â”‚       â”œâ”€â”€ weights/
â”‚       â”œâ”€â”€ plots/
â”‚       â””â”€â”€ results.csv
â”‚
â”œâ”€â”€ ğŸ“‚ model_versions/     # ëª¨ë¸ ë²„ì „ ê´€ë¦¬
â”‚   â”œâ”€â”€ v0.pt
â”‚   â”œâ”€â”€ v1.pt
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ ğŸ“‚ reports/            # ì„±ëŠ¥ ë¦¬í¬íŠ¸
    â””â”€â”€ *.json
```

## ğŸ’¡ ìµœì í™” íŒ

### 1. ë°ì´í„° ì¤€ë¹„
- **Quality over Quantity**: ì–‘ë³´ë‹¤ ì§ˆ
- **Balanced Classes**: í´ë˜ìŠ¤ ê· í˜• ìœ ì§€
- **Data Augmentation**: ë‹¤ì–‘í•œ ë³€í˜• ì ìš©

### 2. í•˜ì´í¼íŒŒë¼ë¯¸í„°
```python
# ì¶”ì²œ ì„¤ì •
config = {
    'epochs': 100,        # ì¶©ë¶„í•œ í•™ìŠµ
    'batch_size': 16,     # GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ
    'learning_rate': 0.01,  # ì´ˆê¸° í•™ìŠµë¥ 
    'patience': 50,       # Early stopping
    'imgsz': 640         # ì…ë ¥ í¬ê¸°
}
```

### 3. ì„±ëŠ¥ í–¥ìƒ
- **Multi-scale Training**: ë‹¤ì–‘í•œ í¬ê¸°ë¡œ í•™ìŠµ
- **Mosaic Augmentation**: 4ê°œ ì´ë¯¸ì§€ ì¡°í•©
- **MixUp**: ì´ë¯¸ì§€ í˜¼í•©

## ğŸ› ë¬¸ì œ í•´ê²°

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
fine_tuner.configure_training(batch_size=8)

# ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ
fine_tuner.configure_training(imgsz=416)
```

### ê³¼ì í•© ë°©ì§€
```python
# Dropout ì¦ê°€
config['dropout'] = 0.2

# Data augmentation ê°•í™”
config['hsv_h'] = 0.015
config['hsv_s'] = 0.7
config['hsv_v'] = 0.4
```

### í•™ìŠµ ì†ë„ ê°œì„ 
```python
# Mixed precision training
config['amp'] = True

# Workers ìˆ˜ ì¦ê°€
config['workers'] = 8
```

## ğŸ“Š ê²°ê³¼ ë¶„ì„

### í•™ìŠµ ê³¡ì„  í™•ì¸
```python
# í•™ìŠµ ê¸°ë¡ ë¡œë“œ
history = pd.read_csv('runs/project/results.csv')

# ì‹œê°í™”
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.plot(history['epoch'], history['train/loss'])
plt.title('Training Loss')

plt.subplot(1, 3, 2)
plt.plot(history['epoch'], history['metrics/mAP50'])
plt.title('mAP@0.5')

plt.subplot(1, 3, 3)
plt.plot(history['epoch'], history['metrics/mAP50-95'])
plt.title('mAP@0.5-0.95')
plt.show()
```

## ğŸ¯ ì‚¬ìš© ì‚¬ë¡€

### 1. ì˜ë£Œ ì˜ìƒ ë¶„ì„
- ì„¸í¬/ì¡°ì§ ê²€ì¶œ
- ë³‘ë³€ ì‹ë³„
- ì •í™•ë„ 95% ì´ìƒ ë‹¬ì„±

### 2. ì œì¡°ì—… í’ˆì§ˆ ê²€ì‚¬
- ë¶ˆëŸ‰í’ˆ ê²€ì¶œ
- ì‹¤ì‹œê°„ ë¼ì¸ ëª¨ë‹ˆí„°ë§
- ì˜¤íƒì§€ìœ¨ 1% ë¯¸ë§Œ

### 3. ììœ¨ì£¼í–‰
- ë³´í–‰ì/ì°¨ëŸ‰ ê²€ì¶œ
- ë„ë¡œ í‘œì§€íŒ ì¸ì‹
- ì‹¤ì‹œê°„ ì²˜ë¦¬ (30+ FPS)

## ğŸ“ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ¤ ê¸°ì—¬

Issuesì™€ Pull RequestsëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤!

## ğŸ“§ ë¬¸ì˜

ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì€ GitHub Issuesì— ë‚¨ê²¨ì£¼ì„¸ìš”.

---

**ì‘ì„±ì**: aebonlee  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2024.11.21